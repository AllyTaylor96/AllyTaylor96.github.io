<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Alasdair Taylor: Audio, Speech + Language - Projects</title><link href="https://allytaylor96.github.io/" rel="alternate"></link><link href="https://allytaylor96.github.io/feeds/projects.atom.xml" rel="self"></link><id>https://allytaylor96.github.io/</id><updated>2024-02-28T17:04:00+00:00</updated><subtitle>Speech + Language ML Engineer</subtitle><entry><title>Upskilling Project: Toxicity Classifier</title><link href="https://allytaylor96.github.io/toxicity-classifier.html" rel="alternate"></link><published>2024-02-28T17:04:00+00:00</published><updated>2024-02-28T17:04:00+00:00</updated><author><name>Alasdair Taylor</name></author><id>tag:allytaylor96.github.io,2024-02-28:/toxicity-classifier.html</id><summary type="html">&lt;p&gt;Additional detail on the Toxicity Classifier upskilling project carried out in Q1 2024.&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;This article will contain some detail on the project carried out in &lt;a href="https://github.com/AllyTaylor96/toxicity-classifier"&gt;the linked Git repo&lt;/a&gt;, where we build a classifier that differentiates between 'toxic' and 'non-toxic' comments.&lt;/p&gt;
&lt;p&gt;To be continued...&lt;/p&gt;</content><category term="Projects"></category><category term="nlp"></category><category term="toxicity"></category><category term="cnn-classification"></category></entry></feed>